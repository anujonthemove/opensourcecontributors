#!/usr/bin/env python3
# Works only for archives from 2015-01-01 -> Present
from datetime import datetime
from datetime import timezone
from pprint import pprint
from termcolor import colored
import argparse
import csv
import dateutil.parser
import fileinput
import glob
import gzip
import itertools
import json
import logging
import os
import os.path
import re
import sys
import urllib.parse


__version__ = '0.0.1'

invocation_id = "{}-{}.log".format(
    os.uname().nodename,
    datetime.now().strftime('%Y%m%d-%H%M%S'))

# Setup logging
log = logging.getLogger('gha-processor[{}]'.format(os.uname().nodename))
logging.Formatter.default_msec_format = '%s.%03d'
log_formatter = logging.Formatter(
    fmt='%(asctime)s:%(name)s:%(levelname)s:%(message)s')
file_log_handler = logging.FileHandler(invocation_id)
console_log_handler = logging.StreamHandler()
file_log_handler.setFormatter(log_formatter)
console_log_handler.setFormatter(log_formatter)
log.addHandler(file_log_handler)
log.addHandler(console_log_handler)
log.setLevel(logging.INFO)

class ValidationError(RuntimeError):
    """Indicates that an Event was created but seems invalid.
    Suggests that the processor is broken.
    """
    pass

class InvalidRecordError(RuntimeError):
    """Indicates that the record being processed contains errors.
    Suggests that the input data is wrong; no fix necessary for processor.
    """
    pass

class Event(object):
    types = dict()

    def __init__(self, raw_event, source_fmt):
        makers = {
            'event': (self.make_common_from_event, self.make_from_event),
            'timeline': (self.make_common_from_timeline, self.make_from_timeline)
        }
        maker = makers.get(source_fmt, None)
        if maker is None:
            raise "source_fmt should either be 'event' (json) or 'timeline' (csv)"
        for m in maker:
            m(raw_event)

    def make_common_from_event(self, raw_event):
        self.type = raw_event['type']
        self._event_id = raw_event['id']
        self.created_at = dateutil.parser.parse(raw_event['created_at']).isoformat()

        if 'actor' in raw_event:
            self.user = raw_event['actor']['login']
            self._user_lower = self.user.lower()
        if 'repo' in raw_event:
            self.repo = raw_event['repo']['name']
            self._repo_lower = self.repo.lower()
        if 'org' in raw_event:
            self.org = raw_event['org']['login']
            self._org_lower = self.org.lower()

    def make_common_from_timeline(self, raw_event):
        self.type = raw_event['type']
        created_at = datetime.strptime(raw_event['created_at'],
                                       '%Y-%m-%d %H:%M:%S')
        created_at = created_at.replace(tzinfo=timezone.utc)
        self.created_at = created_at.isoformat()
        self.user = raw_event['actor']
        self._user_lower = self.user.lower()
        self.org = raw_event['repository_organization']
        self._org_lower = self.org.lower()

        # At different points, "repository_name" means either:
        # owner/project or project (or it's just messed up)
        if '/' in raw_event['repository_name'] and raw_event['repository_name'] != '/':
            self.repo = raw_event['repository_name']
        elif raw_event['repository_owner'] and raw_event['repository_name']:
            self.repo = "{}/{}".format(raw_event['repository_owner'],
                                       raw_event['repository_name'])
        elif raw_event['url']:
            # Seriously? Yes, this (and others) otherwise lack the repo name:
            # SELECT * FROM [githubarchive:year.2014]
            # where payload_head='8824ed4d86f587a2a556248d9abfac790a1cbd3f'
            #                    ^^ this is a PushEvent
            u = urllib.parse.urlparse(raw_event['url'])
            frags = u.path.split('/')
            self.repo = '/'.join(frags[1:3])
        else:
            raise InvalidRecordError("timeline event does not contain repo name")

        self._repo_lower = self.repo.lower()


    def make_from_event(self, raw_event):
        """
        From new API, natively JSON (on/after 2015-01-01)
        """
        raise "{} must override make_from_event".format(self.__class__.__name__)

    def make_from_timeline(self, row):
        """
        From old API (before 2015-01-01)
        """
        raise "{} must override make_from_timeline".format(self.__class__.__name__)

    def _validate(self):
        raise "{} must override _validate".format(self.__class__.__name__)

    def _explode(self, reason):
        raise ValidationError(reason)

    def validate(self):
        """
        Raises ValidationError if something not Kosher is detected
        """
        if not re.match('^[\w\-\.]+/[\w\-\.]+$', self.repo):
            self._explode("repository [{}] doesn't match [owner/project]".format(self.repo))
        self._validate() # child validations

    @classmethod
    def register_event(cls, event_cls):
        cls.types[event_cls.__name__] = event_cls
        return event_cls

    @classmethod
    def from_raw(cls, raw_event, source_fmt):
        """
        Factory method to create appropriate event instance from raw JSON data
        """
        subclass = cls.types.get(raw_event['type'], None)
        if subclass is None:
            return None
        return subclass(raw_event, source_fmt)


register_event = Event.register_event

@register_event
class GollumEvent(Event):
    def make_from_event(self, d):
        self.pages = d['payload']['pages']

    def make_from_timeline(self, d):
        self.pages = [{
            'html_url': d["payload_page_html_url"],
            'summary': d["payload_page_summary"],
            'page_name': d["payload_page_page_name"],
            'action': d["payload_page_action"],
            'title': d["payload_page_title"],
            'sha': d["payload_page_sha"]
        }]

    def _validate(self):
        pass

@register_event
class IssuesEvent(Event):
    def make_from_event(self, d):
        self.action = d['payload']['action']
        issue = d['payload']['issue']
        self.html_url = issue['html_url']
        self.issue_number = issue['number']

    def make_from_timeline(self, d):
        self.action = d['payload_action']
        self.html_url = d['url']
        try:
            self.issue_number = int(d['payload_number'])
        except:
            self.issue_number = None

    def _validate(self):
        pass

@register_event
class PushEvent(Event):
    def make_from_event(self, d):
        p = d['payload']
        self.ref = p['ref']
        self.head = p['head']
        self.before = p['before']
        self.commit_count = p['size']
        self.distinct_commit_count = p['distinct_size']

    def make_from_timeline(self, d):
        # The "commit" here seems to be a random commit in the push.
        # Only one is listed, and it's not the first nor the last. ಠ_๏
        self.ref = d['payload_ref']
        self.head = d['payload_head']
        self.before = None
        self.commit_count = None
        self.distinct_count = None

    def _validate(self):
        pass

@register_event
class CommitCommentEvent(Event):
    def make_from_event(self, raw_event):
        comment = raw_event['payload']['comment']
        self.path = comment['path'] # to file, if applicable
        self.body = comment['body']
        self.comment_id = comment['id']
        self.commit_id = comment['commit_id']
        self.html_url = comment['html_url']

    def _url_from_timeline(self):
        template = "https://github.com/{e.repo}/commit/{e.commit_id}#commitcomment-{e.comment_id}"
        return template.format(e=self)

    def make_from_timeline(self, d):
        self.path = d['payload_comment_path']
        self.body = d['payload_comment_body']
        self.comment_id = d['payload_comment_id']
        self.commit_id = d['payload_commit_id']
        self.html_url = self._url_from_timeline()

    def _validate(self):
        pass


@register_event
class ReleaseEvent(Event):
    def make_from_event(self, raw_event):
        self.action = raw_event['payload']['action']
        r = raw_event['payload']['release']
        self.tag_name = r['tag_name']
        self.download_url = r['html_url']

    def make_from_timeline(self, raw_event):
        self.action = raw_event['payload_action']
        self.download_url = urllib.parse.urldefrag(raw_event['url']).url
        self.tag_name = os.path.basename(self.download_url)

    def _validate(self):
        pass

@register_event
class PublicEvent(Event):
    def make_from_event(self, d):
        pass

    def make_from_timeline(self, d):
        pass

    def _validate(self):
        pass

@register_event
class MemberEvent(Event):
    def make_from_event(self, raw_event):
        p = raw_event['payload']
        self.target_user = p['member']['login']
        self.target_action = p['action']

    def make_from_timeline(self, raw_event):
        self.target_user = raw_event['payload_member_login']
        self.target_action = raw_event['payload_action']

    def _validate(self):
        pass

@register_event
class IssueCommentEvent(Event):
    def make_from_event(self, raw_event):
        p = raw_event['payload']
        self.action = p['action']
        self.issue_number = p['issue']['number']
        self.issue_url = p['issue']['html_url']
        self.comment_url = p['comment']['html_url']
        self.comment_id = p['comment']['id']
        self.comment_body = p['comment']['body']


    def make_from_timeline(self, raw_event):
        self.issue_url = urllib.parse.urldefrag(raw_event['url']).url
        self.action=raw_event.get('payload_action', '') # closed, open, created, null

        # this timeline is so awful. ಠ_ಠ
        try:
            self.issue_number = int(os.path.basename(self.issue_url))
        except:
            self.issue_number = ''

        self.comment_url = raw_event['url']
        self.comment_id = int(raw_event['payload_comment_id'])
        self.comment_body = raw_event['payload_comment_body']

    def _validate(self):
        pass

def make_event_type_filter(event_type):
    def _filter(raw_event):
        return raw_event['type'] == event_type
    return _filter

class EventProcessor(object):
    def __init__(self, source, destination):
        self.source = source
        self.write_event = destination
        self.total_record_count = 0
        self.count = 0 # success
        self.invalid_record_count = 0
        self.process_error_count = 0

    def _make_stats(self):
        duration = (datetime.now() - self.start_time).total_seconds()
        return (self.total_record_count,
                duration,
                self.total_record_count / duration,
                self.count,
                self.invalid_record_count,
                self.process_error_count)

    def process_events(self):
        self.start_time = datetime.now()

        for raw_event, event_source in self.source:
            event = self.process_event(raw_event, event_source)

            if self.total_record_count > 0 and self.total_record_count % 20000 == 0:
                duration = (datetime.now() - self.start_time).total_seconds()
                log.info("processing: {} records in {:.2f} seconds ({:.2f} r/s): {}s {}i {}e".format(
                    *self._make_stats()))
            if event:
                self.write_event(event)
                self.count += 1

            self.total_record_count += 1

        stats = self._make_stats()
        log.info(colored("processing: {} records in {:.2f} seconds ({:.2f} r/s): {}s {}i {}e".format(
            *stats), 'green'))
        log.info(colored("invalid records: {}".format(self.invalid_record_count),
                      'yellow'))
        log.info(colored("processing errors: {}".format(self.process_error_count),
                      'red'))


    def process_event(self, raw_event, source_fmt):
        try:
            event = Event.from_raw(raw_event, source_fmt)
        except InvalidRecordError as e:
            # This is a known invalid record; nothing we can do.
            self.invalid_record_count += 1
            return None

        if event:
            try:
                event.validate()
            except ValidationError as e:
                # This is very bad.
                msg = "{} ({}):\n\t{}\n\t{}".format(
                    colored('Invalid Event', 'red', attrs=['bold']),
                    colored(str(e), 'red'),
                    json.dumps(event.__dict__).strip(),
                    json.dumps(raw_event).strip(),
                )
                log.error(msg)
                self.process_error_count += 1
                return None

            return event

class EventSource(object):
    def __init__(self, path, record_predicate, file_predicate, subscriber=None):
        self.path = path
        self.record_predicate = record_predicate
        self.file_predicate = file_predicate
        self.notify_file_change = subscriber

    def _filenames(self, pattern):
        files = glob.iglob(os.path.join(self.path, pattern))
        return (f for f in files
                if self.file_predicate(f))

    def _open_file(self, path, mode):
        log.info("opening file: {}".format(path))
        if self.notify_file_change:
            self.notify_file_change(path)
        return gzip.open(path,'rt')

class EventEventSource(EventSource):
    """
    Iterate over every event from Event API
    The class name seems idiotic, but the Event data can either come from the
    "Event API" or the "Timeline API" depending on the year.
    """

    def __iter__(self):
        # Iterator for lines of these source files
        lines = fileinput.FileInput(files=self._filenames('*.json.gz'),
                                    openhook=self._open_file)

        events = (json.loads(line) for line in lines)
        return ((event, 'event') for event in events
                if self.record_predicate(event))

class TimelineEventSource(EventSource):
    """
    Iterate over every event from Timeline API (2011-2014)
    """

    def __iter__(self):
        lines = fileinput.FileInput(files=self._filenames('*.csv.gz'),
                                    openhook=self._open_file)
        reader = csv.DictReader(lines)
        return ((line, 'timeline') for line in reader
                if self.record_predicate(line))

class EventSink(object):
    def __init__(self, destination_dir=None):
        self.out_path = '<STDOUT>'
        self.out_stream = sys.stdout
        self.destination_dir = destination_dir

    def already_processed(self, input_path):
        if not self.destination_dir: return False

        sink_path = self.filename_transform(input_path)
        return os.path.exists(sink_path) and os.stat(sink_path).st_size > 0

    def filename_transform(self, input_path):
        if not self.destination_dir: return None

        input_path = os.path.basename(input_path)
        path, path_ext = os.path.splitext(input_path)
        return os.path.join(
            self.destination_dir,
            ''.join([path + '-processed.json', path_ext]))


    def notify_file_change(self, new_path):
        """Rotate our destination file
        """
        if self.destination_dir is None:
            # No place to put file anyway; always go to STDOUT
            return

        new_path = self.filename_transform(new_path)

        log.info("eventsink: changing file: {} -> {}".format(
            self.out_path, new_path
        ))
        if self.out_stream and self.out_stream != sys.stdout:
            self.out_stream.close()
        self.out_path = new_path
        self.out_stream = open(new_path, 'wb')

        path, path_ext = os.path.splitext(new_path)
        if '.gz' in path_ext:
            log.info('eventsink: will gzip output')
            self.out_stream = gzip.open(self.out_stream,'wb')

    def write(self, event):
        output = json.dumps(event.__dict__).strip() + '\n'
        self.out_stream.write(output.encode())

def main(args):
    record_predicate = bool
    if args.match_type:
        record_predicate = make_user_event_filter(args.match_type)

    sink = EventSink(args.output_path)
    file_predicate = lambda f: not sink.already_processed(f)

    sources = []
    if args.events_path:
        source = EventEventSource(args.events_path,
                                  record_predicate,
                                  file_predicate,
                                  sink.notify_file_change)
        sources.append(source)
    if args.timeline_path:
        source = TimelineEventSource(args.timeline_path,
                                     record_predicate,
                                     file_predicate,
                                     sink.notify_file_change)
        sources.append(source)
    source = itertools.chain(*sources)

    processor = EventProcessor(source, sink.write)
    processor.process_events()

if __name__=='__main__':

    parser = argparse.ArgumentParser(description='Process GitHub archive files')
    parser.add_argument('--events-path')
    parser.add_argument('--timeline-path')
    parser.add_argument('--output-path')
    parser.add_argument('--match-type')
    args = parser.parse_args()

    main(args)
